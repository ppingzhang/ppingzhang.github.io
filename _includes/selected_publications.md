<h2 id="Selected Publications" style="margin: 2px 0px 15px;">Selected Publications</h2>

<h4 style="margin:0 10px 0;">LLM/VLM/MLLM/AIGC</h4>

<ul style="margin:0 0 20px;">
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">Under review</span>: <b>Pingping Zhang</b> et al., "<b>When Video Coding Meets Multimodal Large Language Models: A Unified Paradigm for Video Coding</b>" [<a href="https://arxiv.org/pdf/2408.08093">Paper</a>]</li> 
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">Under review</span>: Kecheng Chen, <b>Pingping Zhang</b> et al., "<b>Large Language Models for Lossless Image Compression: Next-Pixel Prediction in Language Space is All You Need</b>" [<a href="https://arxiv.org/pdf/2411.12448">Paper</a>]</li>
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">ICLR 2025</span>: Kecheng Chen, <b>Pingping Zhang</b> et al., "<b>Test-time Adaptation for Image Compression with Distribution Regularization</b>" [<a href="https://arxiv.org/pdf/2410.12191">Paper</a>]</li>
</ul>

<h4 style="margin:0 10px 0;">Image/Video/Point Cloud Compression</h4>

<ul style="margin:0 0 20px;"> 
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">TMM 2024</span>: <b>Pingping Zhang</b>, et al., "<b>HNR-ISC: Hybrid Neural Representation for Image Set Compression</b>" [<a href="https://ieeexplore.ieee.org/document/10814661">Paper</a>]</li>
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">ToMM 2024</span>: Yuyu Xu, <b>Pingping Zhang</b> et al., "<b>RGB-D Data Compression via Bi-Directional Cross-Modal Prior Transfer and Enhanced Entropy Modeling</b>" [<a href="https://dl.acm.org/doi/10.1145/3702997">Paper</a>] [<a href="https://github.com/xyy7/Learning-based-RGB-D-Image-Compression">Code</a>]</li>
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">TCSVT 2023</span>: <b>Pingping Zhang</b>, et al., "<b>Rethinking semantic image compression: Scalable representation with cross-modality transfer</b>" [<a href="https://ieeexplore.ieee.org/document/10032603">Paper</a>] [<a href="https://github.com/ppingzhang/SCMC">Code</a>]</li>
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">ATSIPA 2024</span>: <b>Pingping Zhang</b>, et al., "<b>2D Gaussian Splatting for Image Compression</b>" [<a href="https://www.nowpublishers.com/article/OpenAccessDownload/SIP-20240025">Paper</a>] [<a href="https://github.com/ppingzhang/2DGS_ImageCompression">Code</a>]</li>
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">TCSVT 2023</span>: Jiancong Chen, Meng Wang, <b>Pingping Zhang</b> et al., "<b>Sparse-to-Dense: High Efficiency Rate Control for End-to-end Scale-Adaptive Video Coding</b>" [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10246313&casa_token=qg9CRIW4_WUAAAAA:69PbIFuSX8kC0Rfj1hFS_73KeiExftw0_gyHZUj4ToRlgfz-aF5HJIfAOOXE3j3HMRlBmwfv1w">Paper</a>]</li>
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">Neurocomputing 2023</span>: Rongqun Lin, Meng Wang, <b>Pingping Zhang</b> et al., "<b>Multiple Hypotheses Based Motion Compensation for Learned Video Compression</b>" [<a href="https://dl.acm.org/doi/10.1016/j.neucom.2023.126396">Paper</a>]</li>
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">ACMMM 2024</span>: Xiangrui Liu, Xinju Wu, <b>Pingping Zhang</b> et al., "<b>CompGS: Efficient 3D Scene Representation via Compressed Gaussian Splatting</b>" [<a href="https://arxiv.org/pdf/2404.09458">Paper</a>] [<a href="https://github.com/LiuXiangrui/CompGS">Code</a>]</li>
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">TCSVT 2024</span>: Xinju Wu, <b>Pingping Zhang</b>, et al., "<b>Geometric Prior Based Deep Human Point Cloud Geometry Compression</b>" [<a href="https://arxiv.org/pdf/2305.01309">Paper</a>]</li>
</ul>

<h4 style="margin:0 10px 0;">Image Enhancement</h4>

<ul style="margin:0 0 20px;">
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">TPAMI 2024</span>: Wenhui Wu, Jian Weng, <b>Pingping Zhang</b> et al., "<b>Interpretable Optimization-Inspired Unfolding Network for Low-light Image Enhancement</b>" [<a href="https://ieeexplore.ieee.org/document/10819641">Paper</a>] [<a href="https://github.com/AndersonYong/URetinex-Net-PLUS">Code</a>]</li>
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">TCSVT 2021</span>: <b>Pingping Zhang</b>, et al., "<b>Progressive point cloud upsampling via differentiable rendering</b>" [<a href="https://ieeexplore.ieee.org/document/9496619">Paper</a>] [<a href="https://github.com/ppingzhang/PPU">Code</a>]</li>
  <li><span style="background-color: #e6f2ff; padding: 2px 5px; border-radius: 3px;">CVPR 2022</span>: Wenhui Wu, Jian Weng, <b>Pingping Zhang</b> et al., "<b>URetinex-Net: Retinex-Based Deep Unfolding Network for Low-Light Image Enhancement</b>" [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_URetinex-Net_Retinex-Based_Deep_Unfolding_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf">Paper</a>] [<a href="https://github.com/AndersonYong/URetinex-Net">Code</a>]</li>
</ul>